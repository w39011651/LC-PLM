{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea6643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preprocess\n",
    "\n",
    "data = data_preprocess.run(file_path='./ATP_rmsim.json', slidingwindow=False)\n",
    "\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "for item in data:\n",
    "    while len(item['sequence']) > MAX_LEN:\n",
    "        sequences.append(item['sequence'][:MAX_LEN])\n",
    "        labels.append(item['label'][:MAX_LEN])\n",
    "        item['sequence'] = item['sequence'][MAX_LEN:]\n",
    "        item['label'] = item['label'][MAX_LEN:]\n",
    "    sequences.append(item['sequence'])\n",
    "    labels.append(item['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3e78f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>542522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample amount\n",
       "0         542522\n",
       "1           6250"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "zero_counter = 0\n",
    "ones_counter = 0\n",
    "\n",
    "for l in labels:\n",
    "    zero_counter+=l.count(0)\n",
    "    ones_counter+=l.count(1)\n",
    "\n",
    "pd.DataFrame(columns=['sample amount'], data = [zero_counter, ones_counter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f36fdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovem/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset import FADBindingDataset, split_dataset\n",
    "from esm_model import EsmForSequenceLabeling\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "model = EsmForSequenceLabeling(\"facebook/esm2_t6_8M_UR50D\", 2)\n",
    "dataset = FADBindingDataset(tokenizer, sequences, labels, max_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cc76d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 0, 20,  7,  7,  4, 10, 16,  4, 10,  4,  4,  4, 22, 15, 17, 19, 11,  4,\n",
       "         15, 15, 10, 15,  7,  4,  7, 11,  7,  4,  9,  4, 18,  4, 14,  4,  4, 18,\n",
       "          8,  6, 12,  4, 12, 22,  4, 10,  4, 15, 12, 16,  8,  9, 17,  7, 14, 17,\n",
       "          5, 11,  7, 19, 14, 13, 16, 21, 12, 16,  9,  4, 14,  4, 18, 18,  8, 18,\n",
       "         14, 14, 14,  6,  6,  8, 22,  9,  4,  5, 19,  7, 14,  8, 21,  8, 13,  5,\n",
       "          5, 10, 11, 12, 11,  9,  5,  7, 10, 10,  9, 18, 20, 12, 15, 20, 10,  7,\n",
       "         21,  6, 18,  8,  8,  9, 15, 13, 18,  9, 13, 19,  7, 10, 19, 13, 17, 21,\n",
       "          8,  2]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1836b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "[train_dataset, test_dataset] = split_dataset(dataset, 0.8)\n",
    "[validate_dataset, test_dataset] = split_dataset(test_dataset, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8aec485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "\n",
    "def find_best_evalution(logits, labels):\n",
    "    logits_np = np.array(logits)\n",
    "    labels_np = np.array(labels)\n",
    "    #sigmoid probability\n",
    "    print(logits_np.shape)\n",
    "    probs = 1 / (1 + np.exp(-logits_np[:, :, 1]))#[batch size, sequence length]\n",
    "\n",
    "    labels_flat = labels_np.flatten()\n",
    "    probs_flat = probs.flatten()\n",
    "\n",
    "     # 只取非 padding (-100) 的有效樣本\n",
    "    active_indices = labels_flat != -100\n",
    "    final_labels = labels_flat[active_indices]\n",
    "    final_probs = probs_flat[active_indices]\n",
    "\n",
    "    # 計算 ROC 並找出最佳 G-mean 閾值\n",
    "    fpr, tpr, thresholds = roc_curve(final_labels, final_probs)\n",
    "    gmeans = np.sqrt(tpr * (1 - fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    best_threshold = thresholds[ix]\n",
    "\n",
    "    print(f'Best Threshold: {best_threshold:.3f}, G-Mean: {gmeans[ix]:.3f}')\n",
    "    return best_threshold\n",
    "    \n",
    "\n",
    "def custom_classification_report(logits, labels, test_evalution = False):\n",
    "    \"\"\"Filt the ignore value and return classification report\"\"\"\n",
    "    labels_np = np.array(labels)\n",
    "    logits_np = np.array(logits)\n",
    "    #preds = np.argmax(logits_np, axis=-1).flatten()\n",
    "    if test_evalution:\n",
    "        threshold = find_best_evalution(logits, labels)\n",
    "    else:\n",
    "        threshold = 0.5\n",
    "    probs = 1/(1+np.exp(-logits_np[:,:,1]))\n",
    "    preds = (probs > threshold).astype(int).flatten()\n",
    "    labels_flat = labels_np.flatten()\n",
    "\n",
    "    print(\"Shape of flattened labels:\", labels_flat.shape)\n",
    "    print(\"Shape of flattened predictions:\", preds.shape)\n",
    "\n",
    "    active_indices = labels_flat != -100\n",
    "    final_labels = labels_flat[active_indices]\n",
    "    final_preds = preds[active_indices]\n",
    "    report_str = classification_report(final_labels, final_preds)\n",
    "    report_dict = classification_report(final_labels, final_preds, output_dict=True)\n",
    "    print(report_str)\n",
    "    return report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d051a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "def train_by_dataloader():\n",
    "\n",
    "    writer = SummaryWriter('runs/my_experiment') # TensorBoard writer\n",
    "\n",
    "    ## hyperparameters in yaml file\n",
    "    with open(\"../config/mamba_config.yaml\", \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    learning_rate = config[\"training_arguments\"][\"learning_rate\"]\n",
    "    per_device_train_batch_size = config[\"training_arguments\"][\"per_device_train_batch_size\"]\n",
    "    num_epochs = config[\"training_arguments\"][\"num_train_epochs\"]\n",
    "    warmup_steps = config['training_arguments']['warmup_steps']\n",
    "    log_step = config['training_arguments']['eval_steps']\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    ##\n",
    "\n",
    "    ## create dataloader\n",
    "    train_loader = DataLoader(train_dataset, per_device_train_batch_size, shuffle=True)\n",
    "    validation_loader = DataLoader(validate_dataset, per_device_train_batch_size, shuffle=True)\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "    ## \n",
    "\n",
    "    ## some variable to use\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_f1_score = -float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state_dict = None\n",
    "    global_step = 0\n",
    "    ## \n",
    "\n",
    "    ## move model to GPU\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    ##\n",
    "  \n",
    "    for epoch in range(num_epochs):\n",
    "        \"\"\"Training Loop Start here\"\"\"\n",
    "        model.train()  \n",
    "        total_train_loss = 0  \n",
    "            \n",
    "        for step, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\")):          \n",
    "            inputs = {k:v.to(device) for k,v in batch.items() if k != 'labels'}# 將批次數據移至設備  \n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()# 清除梯度\n",
    "            loss, _ = model(**inputs, labels=labels)  # 前向傳播  \n",
    "            loss.backward()  # 反向傳播和優化  \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            global_step+=1\n",
    "\n",
    "            if global_step % log_step == 0:\n",
    "                avg_train_loss = total_train_loss / (step + 1)\n",
    "                writer.add_scalar('Loss/train', avg_train_loss, global_step)\n",
    "                print(f\"Epoch {epoch+1}, Step {step+1}, Training Loss: {avg_train_loss:.6f}\")\n",
    "                \n",
    "            total_train_loss += loss.item()\n",
    "        \"\"\"Training Loop End here\"\"\"\n",
    "\n",
    "        \"\"\"Validate Loop Start here\"\"\"\n",
    "        model.eval()\n",
    "        total_eval_loss = 0\n",
    "        all_val_logits = []\n",
    "        all_val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(validation_loader, desc=f\"Validation Epoch {epoch+1}\"):\n",
    "                inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                loss, logits = model(**inputs, labels=labels)\n",
    "\n",
    "                total_eval_loss += loss.item()\n",
    "                all_val_logits.extend(logits.cpu().numpy())\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "        \"\"\"Validate Loop End here\"\"\"\n",
    "\n",
    "        \"\"\"Report and Save the weight of the model\"\"\"\n",
    "        report = custom_classification_report(all_val_logits, all_val_labels, True)\n",
    "\n",
    "        avg_eval_loss = total_eval_loss / len(validation_loader)\n",
    "        val_f1_score = report['1']['f1-score']##means Marco-f1-score on 1's sample prediction\n",
    "        print(f\"Validation Loss: {avg_eval_loss:.6f}\")\n",
    "\n",
    "        # Store the model has best performance on the specific indicator like: \n",
    "        # evaluation loss, recall rate or f1-score\n",
    "        ## early stopping part\n",
    "        if avg_eval_loss < best_val_loss:\n",
    "            best_val_loss = avg_eval_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs!\")\n",
    "                break\n",
    "\n",
    "        ## save weight part\n",
    "        if val_f1_score > best_f1_score:\n",
    "            best_f1_score = val_f1_score\n",
    "            best_model_state_dict = model.state_dict() # 保存最佳權重\n",
    "        \"\"\"An epoch end here\"\"\"\n",
    "\n",
    "        writer.add_scalar('Loss/val', avg_eval_loss, epoch + 1)\n",
    "    writer.close()\n",
    "\n",
    "    if best_model_state_dict is not None:\n",
    "        model.load_state_dict(best_model_state_dict)\n",
    "        print(\"Loaded best model weights!\")\n",
    "    else:\n",
    "        print(\"No improvement found during training.\")\n",
    "    # 保存微調後的模型  \n",
    "    torch.save(model.state_dict(), \"esm_atp_binding_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "540ea48d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m helpers\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      4\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from utils import helpers\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "helpers.log(\"Start Training\")\n",
    "trainer = train_by_dataloader()\n",
    "helpers.log(\"End Training\")\n",
    "end_time = time.time()\n",
    "helpers.log(f\"Total Training Time:{end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ac362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 30.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.143, G-Mean: 0.763\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      3635\n",
      "           1       0.12      0.69      0.21       124\n",
      "\n",
      "    accuracy                           0.82      3759\n",
      "   macro avg       0.55      0.76      0.55      3759\n",
      "weighted avg       0.96      0.82      0.88      3759\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 128.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.214, G-Mean: 0.788\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      3713\n",
      "           1       0.10      0.67      0.17        57\n",
      "\n",
      "    accuracy                           0.90      3770\n",
      "   macro avg       0.55      0.79      0.56      3770\n",
      "weighted avg       0.98      0.90      0.94      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation_loader = DataLoader(validate_dataset, batch_size = 4, shuffle = False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 4, shuffle=False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.eval()\n",
    "total_eval_loss = 0\n",
    "all_val_logits = []\n",
    "all_val_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(validation_loader):\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        _, logits = model(**inputs)\n",
    "        all_val_logits.extend(logits.cpu().numpy())\n",
    "        all_val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "custom_classification_report(all_val_logits, all_val_labels, True)\n",
    "all_val_logits = []\n",
    "all_val_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        _, logits = model(**inputs)\n",
    "        all_val_logits.extend(logits.cpu().numpy())\n",
    "        all_val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "custom_classification_report(all_val_logits, all_val_labels, True)\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
