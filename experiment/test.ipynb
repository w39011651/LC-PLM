{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea6643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sequence': 'MKIRFVFILSVLI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KIRFVFILSVLIS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IRFVFILSVLISG', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'RFVFILSVLISGV', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FVFILSVLISGVC', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VFILSVLISGVCC', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FILSVLISGVCCI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ILSVLISGVCCIS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LSVLISGVCCISK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SVLISGVCCISKN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VLISGVCCISKNV', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LISGVCCISKNVS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ISGVCCISKNVSR', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SGVCCISKNVSRR', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'GVCCISKNVSRRV', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VCCISKNVSRRVA', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'CCISKNVSRRVAN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'CISKNVSRRVANR', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ISKNVSRRVANRM', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SKNVSRRVANRMT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KNVSRRVANRMTA', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NVSRRVANRMTAH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VSRRVANRMTAHS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SRRVANRMTAHSR', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'RRVANRMTAHSRF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'RVANRMTAHSRFL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VANRMTAHSRFLF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ANRMTAHSRFLFV', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NRMTAHSRFLFVH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'RMTAHSRFLFVHD', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'MTAHSRFLFVHDK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'TAHSRFLFVHDKY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'AHSRFLFVHDKYK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'HSRFLFVHDKYKR', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SRFLFVHDKYKRN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'RFLFVHDKYKRNK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FLFVHDKYKRNKN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LFVHDKYKRNKNF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FVHDKYKRNKNFK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VHDKYKRNKNFKL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'HDKYKRNKNFKLK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'DKYKRNKNFKLKN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KYKRNKNFKLKNN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YKRNKNFKLKNNK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KRNKNFKLKNNKE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'RNKNFKLKNNKEE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NKNFKLKNNKEEN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KNFKLKNNKEENN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NFKLKNNKEENNF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FKLKNNKEENNFI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KLKNNKEENNFIN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LKNNKEENNFINL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KNNKEENNFINLY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NNKEENNFINLYT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NKEENNFINLYTV', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KEENNFINLYTVK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}, {'sequence': 'EENNFINLYTVKN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}, {'sequence': 'ENNFINLYTVKNP', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}, {'sequence': 'NNFINLYTVKNPL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]}, {'sequence': 'NFINLYTVKNPLK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]}, {'sequence': 'FINLYTVKNPLKC', 'label': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]}, {'sequence': 'INLYTVKNPLKCK', 'label': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NLYTVKNPLKCKI', 'label': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LYTVKNPLKCKIV', 'label': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YTVKNPLKCKIVD', 'label': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'TVKNPLKCKIVDK', 'label': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VKNPLKCKIVDKI', 'label': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KNPLKCKIVDKIN', 'label': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NPLKCKIVDKINL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'PLKCKIVDKINLV', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LKCKIVDKINLVR', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KCKIVDKINLVRP', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'CKIVDKINLVRPN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KIVDKINLVRPNS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IVDKINLVRPNSP', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VDKINLVRPNSPN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'DKINLVRPNSPNE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KINLVRPNSPNEV', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'INLVRPNSPNEVY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NLVRPNSPNEVYH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LVRPNSPNEVYHL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VRPNSPNEVYHLE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'RPNSPNEVYHLEI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'PNSPNEVYHLEIN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NSPNEVYHLEINH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SPNEVYHLEINHN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'PNEVYHLEINHNG', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NEVYHLEINHNGL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'EVYHLEINHNGLF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VYHLEINHNGLFK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YHLEINHNGLFKY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'HLEINHNGLFKYL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LEINHNGLFKYLE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'EINHNGLFKYLEG', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'INHNGLFKYLEGH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NHNGLFKYLEGHT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'HNGLFKYLEGHTC', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NGLFKYLEGHTCG', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'GLFKYLEGHTCGI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LFKYLEGHTCGII', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FKYLEGHTCGIIP', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KYLEGHTCGIIPY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YLEGHTCGIIPYY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LEGHTCGIIPYYN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'EGHTCGIIPYYNE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'GHTCGIIPYYNEL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'HTCGIIPYYNELD', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'TCGIIPYYNELDN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'CGIIPYYNELDNN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'GIIPYYNELDNNP', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IIPYYNELDNNPN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IPYYNELDNNPNN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'PYYNELDNNPNNQ', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YYNELDNNPNNQI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YNELDNNPNNQIN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NELDNNPNNQINK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ELDNNPNNQINKD', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LDNNPNNQINKDH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'DNNPNNQINKDHN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NNPNNQINKDHNI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NPNNQINKDHNII', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'PNNQINKDHNIIN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NNQINKDHNIINT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NQINKDHNIINTT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'QINKDHNIINTTN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'INKDHNIINTTNH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NKDHNIINTTNHT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KDHNIINTTNHTN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'DHNIINTTNHTNH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'HNIINTTNHTNHN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NIINTTNHTNHNN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IINTTNHTNHNNI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'INTTNHTNHNNIA', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NTTNHTNHNNIAL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'TTNHTNHNNIALS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'TNHTNHNNIALSH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NHTNHNNIALSHI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'HTNHNNIALSHIK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'TNHNNIALSHIKK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NHNNIALSHIKKQ', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'HNNIALSHIKKQR', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NNIALSHIKKQRC', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NIALSHIKKQRCA', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}, {'sequence': 'IALSHIKKQRCAR', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}, {'sequence': 'ALSHIKKQRCARL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]}, {'sequence': 'LSHIKKQRCARLY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]}, {'sequence': 'SHIKKQRCARLYS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]}, {'sequence': 'HIKKQRCARLYSI', 'label': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0]}, {'sequence': 'IKKQRCARLYSIS', 'label': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0]}, {'sequence': 'KKQRCARLYSISS', 'label': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0]}, {'sequence': 'KQRCARLYSISSS', 'label': [0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0]}, {'sequence': 'QRCARLYSISSSN', 'label': [0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]}, {'sequence': 'RCARLYSISSSNN', 'label': [0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]}, {'sequence': 'CARLYSISSSNNM', 'label': [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ARLYSISSSNNME', 'label': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'RLYSISSSNNMEN', 'label': [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LYSISSSNNMENL', 'label': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YSISSSNNMENLS', 'label': [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SISSSNNMENLSV', 'label': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ISSSNNMENLSVA', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}, {'sequence': 'SSSNNMENLSVAI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}, {'sequence': 'SSNNMENLSVAIK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]}, {'sequence': 'SNNMENLSVAIKI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]}, {'sequence': 'NNMENLSVAIKIH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]}, {'sequence': 'NMENLSVAIKIHK', 'label': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]}, {'sequence': 'MENLSVAIKIHKY', 'label': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]}, {'sequence': 'ENLSVAIKIHKYE', 'label': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]}, {'sequence': 'NLSVAIKIHKYEQ', 'label': [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]}, {'sequence': 'LSVAIKIHKYEQT', 'label': [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]}, {'sequence': 'SVAIKIHKYEQTE', 'label': [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}, {'sequence': 'VAIKIHKYEQTEN', 'label': [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]}, {'sequence': 'AIKIHKYEQTENA', 'label': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]}, {'sequence': 'IKIHKYEQTENAP', 'label': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KIHKYEQTENAPN', 'label': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IHKYEQTENAPNI', 'label': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'HKYEQTENAPNIT', 'label': [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KYEQTENAPNITN', 'label': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YEQTENAPNITNY', 'label': [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'EQTENAPNITNYG', 'label': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'QTENAPNITNYGY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}, {'sequence': 'TENAPNITNYGYC', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}, {'sequence': 'ENAPNITNYGYCS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]}, {'sequence': 'NAPNITNYGYCSG', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]}, {'sequence': 'APNITNYGYCSGF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]}, {'sequence': 'PNITNYGYCSGFI', 'label': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0]}, {'sequence': 'NITNYGYCSGFIK', 'label': [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0]}, {'sequence': 'ITNYGYCSGFIKN', 'label': [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0]}, {'sequence': 'TNYGYCSGFIKNL', 'label': [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NYGYCSGFIKNLK', 'label': [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YGYCSGFIKNLKI', 'label': [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'GYCSGFIKNLKIN', 'label': [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YCSGFIKNLKIND', 'label': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'CSGFIKNLKINDD', 'label': [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SGFIKNLKINDDI', 'label': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'GFIKNLKINDDIY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FIKNLKINDDIYL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IKNLKINDDIYLT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KNLKINDDIYLTG', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NLKINDDIYLTGA', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LKINDDIYLTGAH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KINDDIYLTGAHG', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'INDDIYLTGAHGY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NDDIYLTGAHGYF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'DDIYLTGAHGYFN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'DIYLTGAHGYFNL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IYLTGAHGYFNLP', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YLTGAHGYFNLPN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LTGAHGYFNLPND', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'TGAHGYFNLPNDA', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'GAHGYFNLPNDAI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'AHGYFNLPNDAIQ', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'HGYFNLPNDAIQK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'GYFNLPNDAIQKN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YFNLPNDAIQKNT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FNLPNDAIQKNTN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NLPNDAIQKNTNF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LPNDAIQKNTNFI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'PNDAIQKNTNFIF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NDAIQKNTNFIFI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'DAIQKNTNFIFIA', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'AIQKNTNFIFIAT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IQKNTNFIFIATG', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'QKNTNFIFIATGT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}, {'sequence': 'KNTNFIFIATGTG', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}, {'sequence': 'NTNFIFIATGTGI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}, {'sequence': 'TNFIFIATGTGIS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]}, {'sequence': 'NFIFIATGTGISP', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]}, {'sequence': 'FIFIATGTGISPY', 'label': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]}, {'sequence': 'IFIATGTGISPYI', 'label': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FIATGTGISPYIS', 'label': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IATGTGISPYISF', 'label': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ATGTGISPYISFL', 'label': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'TGTGISPYISFLK', 'label': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'GTGISPYISFLKK', 'label': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'TGISPYISFLKKL', 'label': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'GISPYISFLKKLF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ISPYISFLKKLFA', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SPYISFLKKLFAY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'PYISFLKKLFAYD', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YISFLKKLFAYDK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ISFLKKLFAYDKN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SFLKKLFAYDKNN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FLKKLFAYDKNNL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LKKLFAYDKNNLY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KKLFAYDKNNLYN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KLFAYDKNNLYNR', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LFAYDKNNLYNRN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FAYDKNNLYNRNS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'AYDKNNLYNRNSN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YDKNNLYNRNSNY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'DKNNLYNRNSNYT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KNNLYNRNSNYTG', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NNLYNRNSNYTGY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NLYNRNSNYTGYI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LYNRNSNYTGYIT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YNRNSNYTGYITI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NRNSNYTGYITIY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'RNSNYTGYITIYY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NSNYTGYITIYYG', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SNYTGYITIYYGV', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NYTGYITIYYGVY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YTGYITIYYGVYN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'TGYITIYYGVYNE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'GYITIYYGVYNED', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YITIYYGVYNEDS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ITIYYGVYNEDSI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'TIYYGVYNEDSIL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IYYGVYNEDSILY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YYGVYNEDSILYL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YGVYNEDSILYLN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'GVYNEDSILYLNE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VYNEDSILYLNEL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YNEDSILYLNELE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NEDSILYLNELEY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'EDSILYLNELEYF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'DSILYLNELEYFQ', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SILYLNELEYFQK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ILYLNELEYFQKM', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LYLNELEYFQKMY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YLNELEYFQKMYP', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LNELEYFQKMYPN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NELEYFQKMYPNN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ELEYFQKMYPNNI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LEYFQKMYPNNIN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'EYFQKMYPNNINI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YFQKMYPNNINIH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FQKMYPNNINIHY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'QKMYPNNINIHYV', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KMYPNNINIHYVF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'MYPNNINIHYVFS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YPNNINIHYVFSY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'PNNINIHYVFSYK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NNINIHYVFSYKQ', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NINIHYVFSYKQN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'INIHYVFSYKQNS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NIHYVFSYKQNSD', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IHYVFSYKQNSDA', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'HYVFSYKQNSDAT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YVFSYKQNSDATS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VFSYKQNSDATSF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FSYKQNSDATSFY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SYKQNSDATSFYV', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YKQNSDATSFYVQ', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KQNSDATSFYVQD', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'QNSDATSFYVQDE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NSDATSFYVQDEI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SDATSFYVQDEIY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'DATSFYVQDEIYK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ATSFYVQDEIYKR', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'TSFYVQDEIYKRK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SFYVQDEIYKRKT', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FYVQDEIYKRKTE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YVQDEIYKRKTEF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VQDEIYKRKTEFL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'QDEIYKRKTEFLN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'DEIYKRKTEFLNL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'EIYKRKTEFLNLF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IYKRKTEFLNLFN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YKRKTEFLNLFNN', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KRKTEFLNLFNNY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'RKTEFLNLFNNYK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KTEFLNLFNNYKC', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'TEFLNLFNNYKCE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'EFLNLFNNYKCEL', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FLNLFNNYKCELY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LNLFNNYKCELYI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NLFNNYKCELYIC', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LFNNYKCELYICG', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'FNNYKCELYICGH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'NNYKCELYICGHK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}, {'sequence': 'NYKCELYICGHKS', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}, {'sequence': 'YKCELYICGHKSI', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}, {'sequence': 'KCELYICGHKSIR', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]}, {'sequence': 'CELYICGHKSIRY', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]}, {'sequence': 'ELYICGHKSIRYK', 'label': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]}, {'sequence': 'LYICGHKSIRYKV', 'label': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YICGHKSIRYKVM', 'label': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ICGHKSIRYKVMD', 'label': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'CGHKSIRYKVMDI', 'label': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'GHKSIRYKVMDIL', 'label': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'HKSIRYKVMDILK', 'label': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KSIRYKVMDILKS', 'label': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SIRYKVMDILKSH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'IRYKVMDILKSHD', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'RYKVMDILKSHDQ', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'YKVMDILKSHDQF', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KVMDILKSHDQFD', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'VMDILKSHDQFDE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'MDILKSHDQFDEK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'DILKSHDQFDEKK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'ILKSHDQFDEKKK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'LKSHDQFDEKKKK', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'KSHDQFDEKKKKR', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'SHDQFDEKKKKRV', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'HDQFDEKKKKRVH', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'DQFDEKKKKRVHV', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'sequence': 'QFDEKKKKRVHVE', 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(item)\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msequence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m>\u001b[39m MAX_LEN:\n\u001b[1;32m     13\u001b[0m         sequences\u001b[38;5;241m.\u001b[39mappend(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m'\u001b[39m][:MAX_LEN])\n\u001b[1;32m     14\u001b[0m         labels\u001b[38;5;241m.\u001b[39mappend(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m][:MAX_LEN])\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import data_preprocess\n",
    "\n",
    "data = data_preprocess.run(slidingwindow=True)\n",
    "\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "for item in data:\n",
    "    while len(item['sequence']) > MAX_LEN:\n",
    "        sequences.append(item['sequence'][:MAX_LEN])\n",
    "        labels.append(item['label'][:MAX_LEN])\n",
    "        item['sequence'] = item['sequence'][MAX_LEN:]\n",
    "        item['label'] = item['label'][MAX_LEN:]\n",
    "    sequences.append(item['sequence'])\n",
    "    labels.append(item['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e78f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample amount\n",
       "0          35045\n",
       "1           1131"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "zero_counter = 0\n",
    "ones_counter = 0\n",
    "\n",
    "for l in labels:\n",
    "    zero_counter+=l.count(0)\n",
    "    ones_counter+=l.count(1)\n",
    "\n",
    "pd.DataFrame(columns=['sample amount'], data = [zero_counter, ones_counter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f36fdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovem/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at ../../LCPLM/ were not used when initializing LcPlmForMaskedLM: ['bimamba.backbone.layers.10.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.10.mixer.mamba_fwd.D', 'bimamba.backbone.layers.10.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.10.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.10.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.10.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.10.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.10.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.10.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.10.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.10.mixer.mamba_rev.D', 'bimamba.backbone.layers.10.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.10.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.10.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.10.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.10.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.10.norm.weight', 'bimamba.backbone.layers.11.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.11.mixer.mamba_fwd.D', 'bimamba.backbone.layers.11.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.11.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.11.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.11.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.11.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.11.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.11.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.11.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.11.mixer.mamba_rev.D', 'bimamba.backbone.layers.11.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.11.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.11.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.11.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.11.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.11.norm.weight', 'bimamba.backbone.layers.12.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.12.mixer.mamba_fwd.D', 'bimamba.backbone.layers.12.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.12.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.12.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.12.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.12.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.12.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.12.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.12.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.12.mixer.mamba_rev.D', 'bimamba.backbone.layers.12.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.12.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.12.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.12.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.12.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.12.norm.weight', 'bimamba.backbone.layers.13.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.13.mixer.mamba_fwd.D', 'bimamba.backbone.layers.13.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.13.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.13.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.13.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.13.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.13.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.13.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.13.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.13.mixer.mamba_rev.D', 'bimamba.backbone.layers.13.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.13.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.13.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.13.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.13.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.13.norm.weight', 'bimamba.backbone.layers.14.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.14.mixer.mamba_fwd.D', 'bimamba.backbone.layers.14.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.14.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.14.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.14.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.14.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.14.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.14.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.14.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.14.mixer.mamba_rev.D', 'bimamba.backbone.layers.14.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.14.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.14.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.14.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.14.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.14.norm.weight', 'bimamba.backbone.layers.15.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.15.mixer.mamba_fwd.D', 'bimamba.backbone.layers.15.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.15.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.15.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.15.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.15.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.15.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.15.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.15.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.15.mixer.mamba_rev.D', 'bimamba.backbone.layers.15.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.15.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.15.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.15.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.15.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.15.norm.weight', 'bimamba.backbone.layers.16.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.16.mixer.mamba_fwd.D', 'bimamba.backbone.layers.16.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.16.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.16.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.16.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.16.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.16.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.16.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.16.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.16.mixer.mamba_rev.D', 'bimamba.backbone.layers.16.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.16.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.16.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.16.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.16.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.16.norm.weight', 'bimamba.backbone.layers.17.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.17.mixer.mamba_fwd.D', 'bimamba.backbone.layers.17.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.17.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.17.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.17.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.17.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.17.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.17.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.17.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.17.mixer.mamba_rev.D', 'bimamba.backbone.layers.17.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.17.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.17.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.17.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.17.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.17.norm.weight', 'bimamba.backbone.layers.18.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.18.mixer.mamba_fwd.D', 'bimamba.backbone.layers.18.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.18.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.18.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.18.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.18.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.18.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.18.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.18.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.18.mixer.mamba_rev.D', 'bimamba.backbone.layers.18.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.18.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.18.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.18.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.18.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.18.norm.weight', 'bimamba.backbone.layers.19.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.19.mixer.mamba_fwd.D', 'bimamba.backbone.layers.19.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.19.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.19.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.19.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.19.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.19.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.19.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.19.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.19.mixer.mamba_rev.D', 'bimamba.backbone.layers.19.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.19.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.19.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.19.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.19.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.19.norm.weight', 'bimamba.backbone.layers.20.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.20.mixer.mamba_fwd.D', 'bimamba.backbone.layers.20.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.20.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.20.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.20.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.20.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.20.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.20.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.20.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.20.mixer.mamba_rev.D', 'bimamba.backbone.layers.20.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.20.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.20.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.20.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.20.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.20.norm.weight', 'bimamba.backbone.layers.21.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.21.mixer.mamba_fwd.D', 'bimamba.backbone.layers.21.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.21.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.21.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.21.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.21.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.21.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.21.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.21.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.21.mixer.mamba_rev.D', 'bimamba.backbone.layers.21.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.21.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.21.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.21.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.21.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.21.norm.weight', 'bimamba.backbone.layers.22.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.22.mixer.mamba_fwd.D', 'bimamba.backbone.layers.22.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.22.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.22.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.22.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.22.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.22.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.22.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.22.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.22.mixer.mamba_rev.D', 'bimamba.backbone.layers.22.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.22.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.22.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.22.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.22.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.22.norm.weight', 'bimamba.backbone.layers.23.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.23.mixer.mamba_fwd.D', 'bimamba.backbone.layers.23.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.23.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.23.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.23.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.23.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.23.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.23.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.23.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.23.mixer.mamba_rev.D', 'bimamba.backbone.layers.23.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.23.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.23.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.23.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.23.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.23.norm.weight', 'bimamba.backbone.layers.24.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.24.mixer.mamba_fwd.D', 'bimamba.backbone.layers.24.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.24.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.24.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.24.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.24.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.24.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.24.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.24.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.24.mixer.mamba_rev.D', 'bimamba.backbone.layers.24.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.24.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.24.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.24.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.24.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.24.norm.weight', 'bimamba.backbone.layers.25.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.25.mixer.mamba_fwd.D', 'bimamba.backbone.layers.25.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.25.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.25.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.25.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.25.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.25.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.25.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.25.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.25.mixer.mamba_rev.D', 'bimamba.backbone.layers.25.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.25.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.25.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.25.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.25.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.25.norm.weight', 'bimamba.backbone.layers.26.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.26.mixer.mamba_fwd.D', 'bimamba.backbone.layers.26.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.26.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.26.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.26.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.26.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.26.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.26.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.26.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.26.mixer.mamba_rev.D', 'bimamba.backbone.layers.26.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.26.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.26.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.26.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.26.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.26.norm.weight', 'bimamba.backbone.layers.27.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.27.mixer.mamba_fwd.D', 'bimamba.backbone.layers.27.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.27.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.27.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.27.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.27.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.27.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.27.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.27.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.27.mixer.mamba_rev.D', 'bimamba.backbone.layers.27.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.27.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.27.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.27.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.27.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.27.norm.weight', 'bimamba.backbone.layers.28.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.28.mixer.mamba_fwd.D', 'bimamba.backbone.layers.28.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.28.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.28.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.28.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.28.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.28.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.28.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.28.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.28.mixer.mamba_rev.D', 'bimamba.backbone.layers.28.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.28.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.28.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.28.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.28.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.28.norm.weight', 'bimamba.backbone.layers.29.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.29.mixer.mamba_fwd.D', 'bimamba.backbone.layers.29.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.29.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.29.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.29.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.29.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.29.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.29.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.29.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.29.mixer.mamba_rev.D', 'bimamba.backbone.layers.29.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.29.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.29.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.29.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.29.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.29.norm.weight', 'bimamba.backbone.layers.30.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.30.mixer.mamba_fwd.D', 'bimamba.backbone.layers.30.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.30.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.30.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.30.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.30.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.30.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.30.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.30.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.30.mixer.mamba_rev.D', 'bimamba.backbone.layers.30.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.30.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.30.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.30.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.30.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.30.norm.weight', 'bimamba.backbone.layers.31.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.31.mixer.mamba_fwd.D', 'bimamba.backbone.layers.31.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.31.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.31.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.31.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.31.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.31.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.31.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.31.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.31.mixer.mamba_rev.D', 'bimamba.backbone.layers.31.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.31.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.31.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.31.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.31.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.31.norm.weight', 'bimamba.backbone.layers.32.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.32.mixer.mamba_fwd.D', 'bimamba.backbone.layers.32.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.32.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.32.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.32.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.32.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.32.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.32.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.32.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.32.mixer.mamba_rev.D', 'bimamba.backbone.layers.32.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.32.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.32.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.32.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.32.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.32.norm.weight', 'bimamba.backbone.layers.33.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.33.mixer.mamba_fwd.D', 'bimamba.backbone.layers.33.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.33.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.33.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.33.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.33.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.33.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.33.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.33.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.33.mixer.mamba_rev.D', 'bimamba.backbone.layers.33.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.33.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.33.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.33.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.33.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.33.norm.weight', 'bimamba.backbone.layers.34.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.34.mixer.mamba_fwd.D', 'bimamba.backbone.layers.34.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.34.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.34.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.34.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.34.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.34.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.34.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.34.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.34.mixer.mamba_rev.D', 'bimamba.backbone.layers.34.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.34.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.34.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.34.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.34.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.34.norm.weight', 'bimamba.backbone.layers.35.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.35.mixer.mamba_fwd.D', 'bimamba.backbone.layers.35.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.35.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.35.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.35.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.35.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.35.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.35.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.35.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.35.mixer.mamba_rev.D', 'bimamba.backbone.layers.35.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.35.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.35.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.35.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.35.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.35.norm.weight', 'bimamba.backbone.layers.36.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.36.mixer.mamba_fwd.D', 'bimamba.backbone.layers.36.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.36.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.36.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.36.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.36.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.36.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.36.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.36.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.36.mixer.mamba_rev.D', 'bimamba.backbone.layers.36.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.36.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.36.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.36.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.36.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.36.norm.weight', 'bimamba.backbone.layers.37.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.37.mixer.mamba_fwd.D', 'bimamba.backbone.layers.37.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.37.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.37.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.37.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.37.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.37.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.37.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.37.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.37.mixer.mamba_rev.D', 'bimamba.backbone.layers.37.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.37.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.37.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.37.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.37.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.37.norm.weight', 'bimamba.backbone.layers.38.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.38.mixer.mamba_fwd.D', 'bimamba.backbone.layers.38.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.38.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.38.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.38.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.38.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.38.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.38.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.38.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.38.mixer.mamba_rev.D', 'bimamba.backbone.layers.38.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.38.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.38.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.38.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.38.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.38.norm.weight', 'bimamba.backbone.layers.39.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.39.mixer.mamba_fwd.D', 'bimamba.backbone.layers.39.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.39.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.39.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.39.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.39.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.39.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.39.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.39.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.39.mixer.mamba_rev.D', 'bimamba.backbone.layers.39.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.39.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.39.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.39.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.39.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.39.norm.weight', 'bimamba.backbone.layers.40.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.40.mixer.mamba_fwd.D', 'bimamba.backbone.layers.40.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.40.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.40.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.40.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.40.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.40.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.40.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.40.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.40.mixer.mamba_rev.D', 'bimamba.backbone.layers.40.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.40.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.40.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.40.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.40.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.40.norm.weight', 'bimamba.backbone.layers.41.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.41.mixer.mamba_fwd.D', 'bimamba.backbone.layers.41.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.41.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.41.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.41.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.41.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.41.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.41.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.41.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.41.mixer.mamba_rev.D', 'bimamba.backbone.layers.41.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.41.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.41.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.41.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.41.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.41.norm.weight', 'bimamba.backbone.layers.42.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.42.mixer.mamba_fwd.D', 'bimamba.backbone.layers.42.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.42.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.42.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.42.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.42.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.42.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.42.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.42.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.42.mixer.mamba_rev.D', 'bimamba.backbone.layers.42.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.42.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.42.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.42.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.42.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.42.norm.weight', 'bimamba.backbone.layers.43.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.43.mixer.mamba_fwd.D', 'bimamba.backbone.layers.43.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.43.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.43.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.43.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.43.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.43.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.43.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.43.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.43.mixer.mamba_rev.D', 'bimamba.backbone.layers.43.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.43.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.43.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.43.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.43.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.43.norm.weight', 'bimamba.backbone.layers.44.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.44.mixer.mamba_fwd.D', 'bimamba.backbone.layers.44.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.44.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.44.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.44.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.44.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.44.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.44.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.44.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.44.mixer.mamba_rev.D', 'bimamba.backbone.layers.44.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.44.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.44.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.44.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.44.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.44.norm.weight', 'bimamba.backbone.layers.45.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.45.mixer.mamba_fwd.D', 'bimamba.backbone.layers.45.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.45.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.45.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.45.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.45.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.45.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.45.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.45.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.45.mixer.mamba_rev.D', 'bimamba.backbone.layers.45.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.45.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.45.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.45.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.45.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.45.norm.weight', 'bimamba.backbone.layers.46.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.46.mixer.mamba_fwd.D', 'bimamba.backbone.layers.46.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.46.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.46.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.46.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.46.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.46.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.46.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.46.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.46.mixer.mamba_rev.D', 'bimamba.backbone.layers.46.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.46.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.46.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.46.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.46.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.46.norm.weight', 'bimamba.backbone.layers.47.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.47.mixer.mamba_fwd.D', 'bimamba.backbone.layers.47.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.47.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.47.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.47.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.47.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.47.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.47.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.47.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.47.mixer.mamba_rev.D', 'bimamba.backbone.layers.47.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.47.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.47.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.47.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.47.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.47.norm.weight', 'bimamba.backbone.layers.8.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.8.mixer.mamba_fwd.D', 'bimamba.backbone.layers.8.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.8.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.8.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.8.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.8.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.8.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.8.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.8.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.8.mixer.mamba_rev.D', 'bimamba.backbone.layers.8.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.8.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.8.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.8.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.8.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.8.norm.weight', 'bimamba.backbone.layers.9.mixer.mamba_fwd.A_log', 'bimamba.backbone.layers.9.mixer.mamba_fwd.D', 'bimamba.backbone.layers.9.mixer.mamba_fwd.conv1d.bias', 'bimamba.backbone.layers.9.mixer.mamba_fwd.conv1d.weight', 'bimamba.backbone.layers.9.mixer.mamba_fwd.dt_proj.bias', 'bimamba.backbone.layers.9.mixer.mamba_fwd.dt_proj.weight', 'bimamba.backbone.layers.9.mixer.mamba_fwd.in_proj.weight', 'bimamba.backbone.layers.9.mixer.mamba_fwd.out_proj.weight', 'bimamba.backbone.layers.9.mixer.mamba_fwd.x_proj.weight', 'bimamba.backbone.layers.9.mixer.mamba_rev.A_log', 'bimamba.backbone.layers.9.mixer.mamba_rev.D', 'bimamba.backbone.layers.9.mixer.mamba_rev.conv1d.bias', 'bimamba.backbone.layers.9.mixer.mamba_rev.conv1d.weight', 'bimamba.backbone.layers.9.mixer.mamba_rev.dt_proj.bias', 'bimamba.backbone.layers.9.mixer.mamba_rev.dt_proj.weight', 'bimamba.backbone.layers.9.mixer.mamba_rev.x_proj.weight', 'bimamba.backbone.layers.9.norm.weight']\n",
      "- This IS expected if you are initializing LcPlmForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LcPlmForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LcPlmForMaskedLM were not initialized from the model checkpoint at ../../LCPLM/ and are newly initialized: ['bimamba.backbone.layers.0.mixer.mamba_rev.in_proj.weight', 'bimamba.backbone.layers.0.mixer.mamba_rev.out_proj.weight', 'bimamba.backbone.layers.1.mixer.mamba_rev.in_proj.weight', 'bimamba.backbone.layers.1.mixer.mamba_rev.out_proj.weight', 'bimamba.backbone.layers.2.mixer.mamba_rev.in_proj.weight', 'bimamba.backbone.layers.2.mixer.mamba_rev.out_proj.weight', 'bimamba.backbone.layers.3.mixer.mamba_rev.in_proj.weight', 'bimamba.backbone.layers.3.mixer.mamba_rev.out_proj.weight', 'bimamba.backbone.layers.4.mixer.mamba_rev.in_proj.weight', 'bimamba.backbone.layers.4.mixer.mamba_rev.out_proj.weight', 'bimamba.backbone.layers.5.mixer.mamba_rev.in_proj.weight', 'bimamba.backbone.layers.5.mixer.mamba_rev.out_proj.weight', 'bimamba.backbone.layers.6.mixer.mamba_rev.in_proj.weight', 'bimamba.backbone.layers.6.mixer.mamba_rev.out_proj.weight', 'bimamba.backbone.layers.7.mixer.mamba_rev.in_proj.weight', 'bimamba.backbone.layers.7.mixer.mamba_rev.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from dataset import FADBindingDataset, split_dataset\n",
    "from model import LCPLMforSequenceLabeling\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "model = LCPLMforSequenceLabeling(\"../../LCPLM/\")\n",
    "dataset = FADBindingDataset(tokenizer, sequences, labels, max_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc76d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 0, 20, 15, 12, 10, 18,  7, 18, 12,  4,  8,  7,  4, 12,  8,  6,  7, 23,\n",
       "         23, 12,  8, 15, 17,  7,  8, 10, 10,  7,  5, 17, 10, 20, 11,  5, 21,  8,\n",
       "         10, 18,  4, 18,  7, 21, 13, 15, 19, 15, 10, 17, 15, 17, 18, 15,  4, 15,\n",
       "         17, 17, 15,  9,  9, 17, 17, 18, 12, 17,  4, 19, 11,  7, 15, 17, 14,  4,\n",
       "         15, 23, 15, 12,  7, 13, 15, 12, 17,  4,  7, 10, 14, 17,  8, 14, 17,  9,\n",
       "          7, 19, 21,  4,  9, 12, 17, 21, 17,  6,  4, 18, 15, 19,  4,  9,  6, 21,\n",
       "         11, 23,  6, 12, 12, 14, 19, 19, 17,  9,  4, 13, 17, 17, 14, 17, 17, 16,\n",
       "         12,  2]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1836b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "[train_dataset, test_dataset] = split_dataset(dataset, 0.8)\n",
    "[validate_dataset, test_dataset] = split_dataset(test_dataset, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aec485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "\n",
    "def find_best_evalution(logits, labels):\n",
    "    logits_np = np.array(logits)\n",
    "    labels_np = np.array(labels)\n",
    "    #sigmoid probability\n",
    "    print(logits_np.shape)\n",
    "    probs = 1 / (1 + np.exp(-logits_np[:, :, 1]))#[batch size, sequence length]\n",
    "\n",
    "    labels_flat = labels_np.flatten()\n",
    "    probs_flat = probs.flatten()\n",
    "\n",
    "     #  padding (-100) \n",
    "    active_indices = labels_flat != -100\n",
    "    final_labels = labels_flat[active_indices]\n",
    "    final_probs = probs_flat[active_indices]\n",
    "\n",
    "    #  ROC  G-mean \n",
    "    fpr, tpr, thresholds = roc_curve(final_labels, final_probs)\n",
    "    gmeans = np.sqrt(tpr * (1 - fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    best_threshold = thresholds[ix]\n",
    "\n",
    "    print(f'Best Threshold: {best_threshold:.3f}, G-Mean: {gmeans[ix]:.3f}')\n",
    "    return best_threshold\n",
    "    \n",
    "\n",
    "def custom_classification_report(logits, labels, test_evalution = False):\n",
    "    \"\"\"Filt the ignore value and return classification report\"\"\"\n",
    "    labels_np = np.array(labels)\n",
    "    logits_np = np.array(logits)\n",
    "    #preds = np.argmax(logits_np, axis=-1).flatten()\n",
    "    if test_evalution:\n",
    "        threshold = find_best_evalution(logits, labels)\n",
    "    else:\n",
    "        threshold = 0.5\n",
    "    probs = 1/(1+np.exp(-logits_np[:,:,1]))\n",
    "    preds = (probs > threshold).astype(int).flatten()\n",
    "    labels_flat = labels_np.flatten()\n",
    "\n",
    "    print(\"Shape of flattened labels:\", labels_flat.shape)\n",
    "    print(\"Shape of flattened predictions:\", preds.shape)\n",
    "\n",
    "    active_indices = labels_flat != -100\n",
    "    final_labels = labels_flat[active_indices]\n",
    "    final_preds = preds[active_indices]\n",
    "    report_str = classification_report(final_labels, final_preds)\n",
    "    report_dict = classification_report(final_labels, final_preds, output_dict=True)\n",
    "    print(report_str)\n",
    "    return report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d051a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "def train_by_dataloader():\n",
    "\n",
    "    writer = SummaryWriter('runs/my_experiment') # TensorBoard writer\n",
    "\n",
    "    ## hyperparameters in yaml file\n",
    "    with open(\"../config/mamba_config.yaml\", \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    learning_rate = config[\"training_arguments\"][\"learning_rate\"]\n",
    "    per_device_train_batch_size = config[\"training_arguments\"][\"per_device_train_batch_size\"]\n",
    "    num_epochs = config[\"training_arguments\"][\"num_train_epochs\"]\n",
    "    warmup_steps = config['training_arguments']['warmup_steps']\n",
    "    log_step = config['training_arguments']['eval_steps']\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    ##\n",
    "\n",
    "    ## create dataloader\n",
    "    train_loader = DataLoader(train_dataset, per_device_train_batch_size, shuffle=True)\n",
    "    validation_loader = DataLoader(validate_dataset, per_device_train_batch_size, shuffle=True)\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "    ## \n",
    "\n",
    "    ## some variable to use\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_f1_score = -float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state_dict = None\n",
    "    global_step = 0\n",
    "    ## \n",
    "\n",
    "    ## move model to GPU\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    ##\n",
    "  \n",
    "    for epoch in range(num_epochs):\n",
    "        \"\"\"Training Loop Start here\"\"\"\n",
    "        model.train()  \n",
    "        total_train_loss = 0  \n",
    "            \n",
    "        for step, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\")):          \n",
    "            inputs = {k:v.to(device) for k,v in batch.items() if k != 'labels'}#   \n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()# \n",
    "            loss, _ = model(**inputs, labels=labels)  #   \n",
    "            loss.backward()  #   \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            global_step+=1\n",
    "\n",
    "            if global_step % log_step == 0:\n",
    "                avg_train_loss = total_train_loss / (step + 1)\n",
    "                writer.add_scalar('Loss/train', avg_train_loss, global_step)\n",
    "                print(f\"Epoch {epoch+1}, Step {step+1}, Training Loss: {avg_train_loss:.6f}\")\n",
    "                \n",
    "            total_train_loss += loss.item()\n",
    "        \"\"\"Training Loop End here\"\"\"\n",
    "\n",
    "        \"\"\"Validate Loop Start here\"\"\"\n",
    "        model.eval()\n",
    "        total_eval_loss = 0\n",
    "        all_val_logits = []\n",
    "        all_val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(validation_loader, desc=f\"Validation Epoch {epoch+1}\"):\n",
    "                inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                loss, logits = model(**inputs, labels=labels)\n",
    "\n",
    "                total_eval_loss += loss.item()\n",
    "                all_val_logits.extend(logits.cpu().numpy())\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "        \"\"\"Validate Loop End here\"\"\"\n",
    "\n",
    "        \"\"\"Report and Save the weight of the model\"\"\"\n",
    "        report = custom_classification_report(all_val_logits, all_val_labels, True)\n",
    "\n",
    "        avg_eval_loss = total_eval_loss / len(validation_loader)\n",
    "        val_f1_score = report['1']['f1-score']##means Marco-f1-score on 1's sample prediction\n",
    "        print(f\"Validation Loss: {avg_eval_loss:.6f}\")\n",
    "\n",
    "        # Store the model has best performance on the specific indicator like: \n",
    "        # evaluation loss, recall rate or f1-score\n",
    "        ## early stopping part\n",
    "        if avg_eval_loss < best_val_loss:\n",
    "            best_val_loss = avg_eval_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs!\")\n",
    "                break\n",
    "\n",
    "        ## save weight part\n",
    "        if val_f1_score > best_f1_score:\n",
    "            best_f1_score = val_f1_score\n",
    "            best_model_state_dict = model.state_dict() # \n",
    "        \"\"\"An epoch end here\"\"\"\n",
    "\n",
    "        writer.add_scalar('Loss/val', avg_eval_loss, epoch + 1)\n",
    "    writer.close()\n",
    "\n",
    "    if best_model_state_dict is not None:\n",
    "        model.load_state_dict(best_model_state_dict)\n",
    "        print(\"Loaded best model weights!\")\n",
    "    else:\n",
    "        print(\"No improvement found during training.\")\n",
    "    #   \n",
    "    torch.save(model.state_dict(), \"fad_binding_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540ea48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 1:   3%|         | 1/32 [00:06<03:25,  6.64s/it]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 1: 100%|| 32/32 [00:17<00:00,  1.88it/s]\n",
      "Validation Epoch 1: 100%|| 4/4 [00:00<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.475, G-Mean: 0.568\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.54      0.69      3661\n",
      "           1       0.04      0.59      0.07       105\n",
      "\n",
      "    accuracy                           0.54      3766\n",
      "   macro avg       0.51      0.56      0.38      3766\n",
      "weighted avg       0.95      0.54      0.68      3766\n",
      "\n",
      "Validation Loss: 0.157775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 2:  22%|       | 7/32 [00:02<00:08,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 8, Training Loss: 0.138152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|| 32/32 [00:10<00:00,  2.99it/s]\n",
      "Validation Epoch 2: 100%|| 4/4 [00:00<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.449, G-Mean: 0.554\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.51      0.67      3661\n",
      "           1       0.03      0.59      0.06       105\n",
      "\n",
      "    accuracy                           0.51      3766\n",
      "   macro avg       0.51      0.55      0.37      3766\n",
      "weighted avg       0.95      0.51      0.65      3766\n",
      "\n",
      "Validation Loss: 0.109713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 3:  47%|     | 15/32 [00:05<00:05,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Step 16, Training Loss: 0.088981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|| 32/32 [00:11<00:00,  2.89it/s]\n",
      "Validation Epoch 3: 100%|| 4/4 [00:00<00:00, 11.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.366, G-Mean: 0.507\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.61      0.75      3661\n",
      "           1       0.03      0.41      0.06       105\n",
      "\n",
      "    accuracy                           0.61      3766\n",
      "   macro avg       0.50      0.51      0.40      3766\n",
      "weighted avg       0.95      0.61      0.73      3766\n",
      "\n",
      "Validation Loss: 0.022265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 4:  72%|  | 23/32 [00:08<00:03,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Step 24, Training Loss: 0.011926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|| 32/32 [00:11<00:00,  2.91it/s]\n",
      "Validation Epoch 4: 100%|| 4/4 [00:00<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.182, G-Mean: 0.584\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.44      0.61      3661\n",
      "           1       0.04      0.76      0.07       105\n",
      "\n",
      "    accuracy                           0.45      3766\n",
      "   macro avg       0.51      0.60      0.34      3766\n",
      "weighted avg       0.96      0.45      0.59      3766\n",
      "\n",
      "Validation Loss: 0.003260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 5: 100%|| 32/32 [00:10<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Step 32, Training Loss: 0.004667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 5: 100%|| 4/4 [00:00<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.215, G-Mean: 0.714\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.72      0.83      3661\n",
      "           1       0.07      0.70      0.12       105\n",
      "\n",
      "    accuracy                           0.72      3766\n",
      "   macro avg       0.53      0.71      0.48      3766\n",
      "weighted avg       0.96      0.72      0.81      3766\n",
      "\n",
      "Validation Loss: 0.002231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 6: 100%|| 32/32 [00:10<00:00,  2.93it/s]\n",
      "Validation Epoch 6: 100%|| 4/4 [00:00<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.288, G-Mean: 0.779\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      3661\n",
      "           1       0.13      0.70      0.21       105\n",
      "\n",
      "    accuracy                           0.86      3766\n",
      "   macro avg       0.56      0.78      0.57      3766\n",
      "weighted avg       0.97      0.86      0.90      3766\n",
      "\n",
      "Validation Loss: 0.002027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 7:  22%|       | 7/32 [00:02<00:08,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Step 8, Training Loss: 0.002269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|| 32/32 [00:11<00:00,  2.87it/s]\n",
      "Validation Epoch 7: 100%|| 4/4 [00:00<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.250, G-Mean: 0.779\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      3661\n",
      "           1       0.11      0.72      0.19       105\n",
      "\n",
      "    accuracy                           0.82      3766\n",
      "   macro avg       0.55      0.78      0.54      3766\n",
      "weighted avg       0.97      0.82      0.88      3766\n",
      "\n",
      "Validation Loss: 0.001349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 8:  47%|     | 15/32 [00:05<00:06,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Step 16, Training Loss: 0.002353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|| 32/32 [00:11<00:00,  2.86it/s]\n",
      "Validation Epoch 8: 100%|| 4/4 [00:00<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.261, G-Mean: 0.770\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      3661\n",
      "           1       0.16      0.65      0.26       105\n",
      "\n",
      "    accuracy                           0.89      3766\n",
      "   macro avg       0.57      0.77      0.60      3766\n",
      "weighted avg       0.97      0.89      0.92      3766\n",
      "\n",
      "Validation Loss: 0.000869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 9:  72%|  | 23/32 [00:08<00:03,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Step 24, Training Loss: 0.001548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|| 32/32 [00:11<00:00,  2.89it/s]\n",
      "Validation Epoch 9: 100%|| 4/4 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.213, G-Mean: 0.771\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94      3661\n",
      "           1       0.15      0.66      0.24       105\n",
      "\n",
      "    accuracy                           0.89      3766\n",
      "   macro avg       0.57      0.77      0.59      3766\n",
      "weighted avg       0.97      0.89      0.92      3766\n",
      "\n",
      "Validation Loss: 0.001518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 10: 100%|| 32/32 [00:11<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Step 32, Training Loss: 0.001203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 10: 100%|| 4/4 [00:00<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.184, G-Mean: 0.772\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      3661\n",
      "           1       0.14      0.67      0.23       105\n",
      "\n",
      "    accuracy                           0.87      3766\n",
      "   macro avg       0.56      0.77      0.58      3766\n",
      "weighted avg       0.97      0.87      0.91      3766\n",
      "\n",
      "Validation Loss: 0.000708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 11: 100%|| 32/32 [00:11<00:00,  2.88it/s]\n",
      "Validation Epoch 11: 100%|| 4/4 [00:00<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.249, G-Mean: 0.777\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      3661\n",
      "           1       0.31      0.62      0.42       105\n",
      "\n",
      "    accuracy                           0.95      3766\n",
      "   macro avg       0.65      0.79      0.70      3766\n",
      "weighted avg       0.97      0.95      0.96      3766\n",
      "\n",
      "Validation Loss: 0.000696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 12:  22%|       | 7/32 [00:02<00:08,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Step 8, Training Loss: 0.000798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|| 32/32 [00:11<00:00,  2.87it/s]\n",
      "Validation Epoch 12: 100%|| 4/4 [00:00<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.156, G-Mean: 0.791\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87      3661\n",
      "           1       0.09      0.79      0.17       105\n",
      "\n",
      "    accuracy                           0.78      3766\n",
      "   macro avg       0.54      0.79      0.52      3766\n",
      "weighted avg       0.97      0.78      0.86      3766\n",
      "\n",
      "Validation Loss: 0.000807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 13:  47%|     | 15/32 [00:05<00:06,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Step 16, Training Loss: 0.000489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|| 32/32 [00:11<00:00,  2.84it/s]\n",
      "Validation Epoch 13: 100%|| 4/4 [00:00<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.146, G-Mean: 0.794\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89      3661\n",
      "           1       0.10      0.77      0.18       105\n",
      "\n",
      "    accuracy                           0.81      3766\n",
      "   macro avg       0.55      0.79      0.54      3766\n",
      "weighted avg       0.97      0.81      0.87      3766\n",
      "\n",
      "Validation Loss: 0.000508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 14:  72%|  | 23/32 [00:08<00:03,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Step 24, Training Loss: 0.000309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|| 32/32 [00:11<00:00,  2.85it/s]\n",
      "Validation Epoch 14: 100%|| 4/4 [00:00<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.193, G-Mean: 0.826\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92      3661\n",
      "           1       0.13      0.79      0.23       105\n",
      "\n",
      "    accuracy                           0.85      3766\n",
      "   macro avg       0.56      0.82      0.57      3766\n",
      "weighted avg       0.97      0.85      0.90      3766\n",
      "\n",
      "Validation Loss: 0.000963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 15: 100%|| 32/32 [00:11<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Step 32, Training Loss: 0.000422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 15: 100%|| 4/4 [00:00<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.127, G-Mean: 0.785\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88      3661\n",
      "           1       0.10      0.76      0.17       105\n",
      "\n",
      "    accuracy                           0.80      3766\n",
      "   macro avg       0.54      0.78      0.53      3766\n",
      "weighted avg       0.97      0.80      0.87      3766\n",
      "\n",
      "Validation Loss: 0.000904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 16: 100%|| 32/32 [00:11<00:00,  2.84it/s]\n",
      "Validation Epoch 16: 100%|| 4/4 [00:00<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.149, G-Mean: 0.849\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93      3661\n",
      "           1       0.15      0.82      0.26       105\n",
      "\n",
      "    accuracy                           0.87      3766\n",
      "   macro avg       0.57      0.84      0.59      3766\n",
      "weighted avg       0.97      0.87      0.91      3766\n",
      "\n",
      "Validation Loss: 0.000436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 17:  22%|       | 7/32 [00:02<00:08,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Step 8, Training Loss: 0.000225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|| 32/32 [00:11<00:00,  2.84it/s]\n",
      "Validation Epoch 17: 100%|| 4/4 [00:00<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.168, G-Mean: 0.854\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96      3661\n",
      "           1       0.23      0.78      0.35       105\n",
      "\n",
      "    accuracy                           0.92      3766\n",
      "   macro avg       0.61      0.85      0.65      3766\n",
      "weighted avg       0.97      0.92      0.94      3766\n",
      "\n",
      "Validation Loss: 0.000675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 18:  47%|     | 15/32 [00:05<00:06,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Step 16, Training Loss: 0.000158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|| 32/32 [00:11<00:00,  2.82it/s]\n",
      "Validation Epoch 18: 100%|| 4/4 [00:00<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.166, G-Mean: 0.855\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      3661\n",
      "           1       0.23      0.78      0.36       105\n",
      "\n",
      "    accuracy                           0.92      3766\n",
      "   macro avg       0.61      0.85      0.66      3766\n",
      "weighted avg       0.97      0.92      0.94      3766\n",
      "\n",
      "Validation Loss: 0.000700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 19:  72%|  | 23/32 [00:08<00:03,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Step 24, Training Loss: 0.000119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|| 32/32 [00:11<00:00,  2.86it/s]\n",
      "Validation Epoch 19: 100%|| 4/4 [00:00<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.218, G-Mean: 0.859\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      3661\n",
      "           1       0.25      0.78      0.38       105\n",
      "\n",
      "    accuracy                           0.93      3766\n",
      "   macro avg       0.62      0.86      0.67      3766\n",
      "weighted avg       0.97      0.93      0.95      3766\n",
      "\n",
      "Validation Loss: 0.000423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 20: 100%|| 32/32 [00:11<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Step 32, Training Loss: 0.000094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 20: 100%|| 4/4 [00:00<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.176, G-Mean: 0.851\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      3661\n",
      "           1       0.23      0.77      0.36       105\n",
      "\n",
      "    accuracy                           0.92      3766\n",
      "   macro avg       0.61      0.85      0.66      3766\n",
      "weighted avg       0.97      0.92      0.94      3766\n",
      "\n",
      "Validation Loss: 0.000516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 21: 100%|| 32/32 [00:11<00:00,  2.83it/s]\n",
      "Validation Epoch 21: 100%|| 4/4 [00:00<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.155, G-Mean: 0.832\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      3661\n",
      "           1       0.19      0.75      0.30       105\n",
      "\n",
      "    accuracy                           0.90      3766\n",
      "   macro avg       0.59      0.83      0.63      3766\n",
      "weighted avg       0.97      0.90      0.93      3766\n",
      "\n",
      "Validation Loss: 0.000759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 22:  22%|       | 7/32 [00:02<00:09,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Step 8, Training Loss: 0.000098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|| 32/32 [00:11<00:00,  2.82it/s]\n",
      "Validation Epoch 22: 100%|| 4/4 [00:00<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.145, G-Mean: 0.841\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      3661\n",
      "           1       0.19      0.77      0.31       105\n",
      "\n",
      "    accuracy                           0.90      3766\n",
      "   macro avg       0.59      0.84      0.63      3766\n",
      "weighted avg       0.97      0.90      0.93      3766\n",
      "\n",
      "Validation Loss: 0.001026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 23:  47%|     | 15/32 [00:05<00:06,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Step 16, Training Loss: 0.000036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|| 32/32 [00:11<00:00,  2.82it/s]\n",
      "Validation Epoch 23: 100%|| 4/4 [00:00<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.131, G-Mean: 0.836\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      3661\n",
      "           1       0.21      0.75      0.33       105\n",
      "\n",
      "    accuracy                           0.91      3766\n",
      "   macro avg       0.60      0.84      0.64      3766\n",
      "weighted avg       0.97      0.91      0.94      3766\n",
      "\n",
      "Validation Loss: 0.000794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24:   0%|          | 0/32 [00:00<?, ?it/s]/home/lovem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 24:  72%|  | 23/32 [00:08<00:03,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Step 24, Training Loss: 0.000040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|| 32/32 [00:11<00:00,  2.81it/s]\n",
      "Validation Epoch 24: 100%|| 4/4 [00:00<00:00, 10.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.116, G-Mean: 0.837\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      3661\n",
      "           1       0.18      0.77      0.29       105\n",
      "\n",
      "    accuracy                           0.89      3766\n",
      "   macro avg       0.58      0.83      0.62      3766\n",
      "weighted avg       0.97      0.89      0.92      3766\n",
      "\n",
      "Validation Loss: 0.000477\n",
      "Early stopping triggered after 24 epochs!\n",
      "Loaded best model weights!\n"
     ]
    }
   ],
   "source": [
    "trainer = train_by_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ac362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8/8 [00:00<00:00, 13.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 2)\n",
      "Best Threshold: 0.140, G-Mean: 0.838\n",
      "Shape of flattened labels: (4096,)\n",
      "Shape of flattened predictions: (4096,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      3604\n",
      "           1       0.23      0.74      0.35        97\n",
      "\n",
      "    accuracy                           0.93      3701\n",
      "   macro avg       0.61      0.84      0.66      3701\n",
      "weighted avg       0.97      0.93      0.95      3701\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size = 4, shuffle=False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.eval()\n",
    "total_eval_loss = 0\n",
    "all_val_logits = []\n",
    "all_val_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        _, logits = model(**inputs)\n",
    "        all_val_logits.extend(logits.cpu().numpy())\n",
    "        all_val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "custom_classification_report(all_val_logits, all_val_labels, True)\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
